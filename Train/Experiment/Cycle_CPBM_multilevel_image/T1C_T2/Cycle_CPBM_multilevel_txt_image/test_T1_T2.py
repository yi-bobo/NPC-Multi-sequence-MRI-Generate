import sys
import os
import torch
import random
import logging
import warnings
import numpy as np
from torch.utils.data import DataLoader

# è‡ªå®šä¹‰æ¨¡å—å¯¼å…¥
warnings.filterwarnings('ignore')    # å¿½ç•¥è­¦å‘Š
sys.path.append('/data1/weiyibo/NPC-MRI/Code/Pctch_model/')
from Model.Cycle_CPBM_model import Cycle_CPBM_model
from Dataset.patch_dataset import npy_3D_dataset
from Utils.path_util import create_directories
from Utils.config_util import load_yaml_config, log_namespace
from Utils.logging_util import setup_logging, save_loss_csv
from Utils.save_load_model_util import load_model


def set_random_seed(seed):
    """è®¾ç½®éšæœºç§å­"""
    torch.manual_seed(seed)
    np.random.seed(seed)
    random.seed(seed)

def initialize_dataloader(opt):
    """åˆå§‹åŒ–æ•°æ®åŠ è½½å™¨"""
    logging.info("========== â³åŠ è½½æ•°æ®é›†â³ ==========")
    train_dataset = npy_3D_dataset(opt.data, mode='train')
    train_loader = DataLoader(
        train_dataset, 
        batch_size=opt.train.batch_size, 
        shuffle=True, 
        num_workers=opt.train.num_workers, 
        drop_last=True
    )
    logging.info(f"è®­ç»ƒé›†å¤§å°: {len(train_dataset)}, æ‰¹æ¬¡æ•°: {len(train_loader)}")

    val_dataset = npy_3D_dataset(opt.data, mode='val')
    val_loader = DataLoader(val_dataset, batch_size=1, shuffle=False, num_workers=1)
    logging.info(f"éªŒè¯é›†å¤§å°: {len(val_dataset)}, æ‰¹æ¬¡æ•°: {len(val_loader)}")

    test_dataset = npy_3D_dataset(opt.data, mode='test')
    test_loader = DataLoader(test_dataset, batch_size=1, shuffle=False, num_workers=1)
    logging.info(f"æµ‹è¯•é›†å¤§å°: {len(test_dataset)}, æ‰¹æ¬¡æ•°: {len(test_loader)}")
    logging.info("========== âŒ›æ•°æ®é›†åŠ è½½å®Œæ¯•âŒ› ==========")

    return train_loader, val_loader, test_loader


def test_model(model, test_loader, epoch, opt, model_name):
    """éªŒè¯æ¨¡å‹"""
    logging.info(f"ğŸ€å¼€å§‹å¯¹æ¨¡å‹{model_name}è¿›è¡Œæµ‹è¯•")
    mae_x0_list, ssim_x0_list, psnr_x0_list, mae_xT_list, ssim_xT_list, psnr_xT_list = [], [], [], [], [], []

    with torch.no_grad():
        for i, data in enumerate(test_loader):
        # for i, data in zip(range(2), test_loader):
            x_0, x_T, txt_con, _, img_con, _, patient_id, data_mapping = model.set_input(data)
            x0, xT, pred_x0, pred_xT, mae_x0, ssim_x0, psnr_x0, mae_xT, ssim_xT, psnr_xT = model.val(x_0, x_T, txt_con, img_con )
            
            mae_x0_list.append(mae_x0)
            ssim_x0_list.append(ssim_x0)
            psnr_x0_list.append(psnr_x0)
            mae_xT_list.append(mae_xT)
            ssim_xT_list.append(ssim_xT)
            psnr_xT_list.append(psnr_xT)

            # ä¿å­˜å•ä¸ªæ ·æœ¬éªŒè¯ç»“æœ
            test_cal_dict = {'patient_id': patient_id, 'MAE_x0': mae_x0, 'SSIM_x0': ssim_x0, 'PSNR_x0': psnr_x0, 
                            'MAE_xT': mae_xT, 'SSIM_xT': ssim_xT, 'PSNR_xT': psnr_xT}
            logging.info(f"æµ‹è¯•é›†epoch_{epoch}æ¨¡å‹çš„patient_id:{patient_id}çš„æµ‹è¯•ç»“æœ:"
                         f"MAE_x0:{mae_x0:.4f}, SSIM_x0:{ssim_x0:.4f}, PSNR_x0:{psnr_x0:.4f}, "
                         f"MAE_xT:{mae_xT:.4f}, SSIM_xT:{ssim_xT:.4f}, PSNR_xT:{psnr_xT:.4f}")
            save_loss_csv(
                file_path=opt.path.test_metric_csv_path,
                epoch=epoch,
                header=['epoch', 'patient_id', 'MAE_x0', 'SSIM_x0', 'PSNR_x0', 'MAE_xT', 'SSIM_xT', 'PSNR_xT'],
                loss_dict=test_cal_dict
            )

            save_path_dir = os.path.join(opt.path.img_path_dir, 'test', f"{model_name}_{epoch}", patient_id)
            os.makedirs(save_path_dir, exist_ok=True)
            model.plot(x0, xT, pred_x0, pred_xT, data_mapping, save_path_dir)

    # è®¡ç®—éªŒè¯é›†å¹³å‡å€¼ä¸æ ‡å‡†å·®
    metrics_avg = {
        'MAE_x0': (np.mean(mae_x0_list), np.std(mae_x0_list)),
        'SSIM_x0': (np.mean(ssim_x0_list), np.std(ssim_x0_list)),
        'PSNR_x0': (np.mean(psnr_x0_list), np.std(psnr_x0_list)),
        'MAE_xT': (np.mean(mae_xT_list), np.std(mae_xT_list)),
        'SSIM_xT': (np.mean(ssim_xT_list), np.std(ssim_xT_list)),
        'PSNR_xT': (np.mean(psnr_xT_list), np.std(psnr_xT_list)),
    }
    # æ ¼å¼åŒ–è¾“å‡ºç»“æœ
    metrics_str = (
        f"MAE_x0: {metrics_avg['MAE_x0'][0]:.6f} Â± {metrics_avg['MAE_x0'][1]:.6f}, "
        f"SSIM_x0: {metrics_avg['SSIM_x0'][0]:.6f} Â± {metrics_avg['SSIM_x0'][1]:.6f}, "
        f"PSNR_x0: {metrics_avg['PSNR_x0'][0]:.6f} Â± {metrics_avg['PSNR_x0'][1]:.6f}, "
        f"MAE_xT: {metrics_avg['MAE_xT'][0]:.6f} Â± {metrics_avg['MAE_xT'][1]:.6f}, "
        f"SSIM_xT: {metrics_avg['SSIM_xT'][0]:.6f} Â± {metrics_avg['SSIM_xT'][1]:.6f}, "
        f"PSNR_xT: {metrics_avg['PSNR_xT'][0]:.6f} Â± {metrics_avg['PSNR_xT'][1]:.6f}"
    )
    logging.info(f"æµ‹è¯•é›†{model_name}åœ¨epoch_{epoch}æ¨¡å‹çš„æµ‹è¯•ç»“æœ: {metrics_str}")
    
    # ä¿å­˜éªŒè¯é›†ç»“æœ
    save_loss_csv(
        file_path=opt.path.test_avg_metric_csv_path,
        epoch=epoch,
        header=['epoch', 'MAE_x0', 'SSIM_x0', 'PSNR_x0', 'MAE_xT', 'SSIM_xT', 'PSNR_xT'],
        loss_dict={key: f"{test[0]:.4f} Â± {test[1]:.4f}" for key, test in metrics_avg.items()}
    )


def main():
    # 1ï¸âƒ£ åŠ è½½é…ç½®
    config_path = "./Config/Cycle_CPBM_multilevel_txt_image/T1_T2.yaml"
    opt = load_yaml_config(config_path)

    # 1.1 è®¾ç½®éšæœºç§å­ä¸ä¿å­˜è·¯å¾„
    set_random_seed(opt.train.seed)
    create_directories(opt)

    # 2ï¸âƒ£ é…ç½®æ—¥å¿—
    setup_logging(opt, mode='test')
    logging.info("========== â³è®­ç»ƒé…ç½®å‚æ•°â³ ==========")
    log_namespace(opt)

    # 3ï¸âƒ£ é€‰æ‹©è®¾å¤‡
    if opt.train.multi_gpu:
        os.environ['CUDA_VISIBLE_DEVICES'] = f'{opt.train.gpu}'
        opt.train.device = torch.device(f"cuda:0" if torch.cuda.is_available() else "cpu")
        available_gpus = torch.cuda.device_count()
        opt.train.batch_size = int(opt.train.batch_size * available_gpus)  # åŠ¨æ€è°ƒæ•´ batch_size
        logging.info(f"ä½¿ç”¨ {available_gpus} ä¸ª GPU, æ›´æ–° batch_size ä¸º {opt.train.batch_size}")
    else:
        opt.train.device = torch.device(f"cuda:{opt.train.gpu}" if torch.cuda.is_available() else "cpu")
        logging.info(f"ä½¿ç”¨è®¾å¤‡: {opt.train.device}")

    # 4ï¸âƒ£ åŠ è½½æ•°æ®é›†
    _, _, test_loader = initialize_dataloader(opt)

    # 5ï¸âƒ£ åˆ›å»ºæ¨¡å‹
    model = Cycle_CPBM_model(opt).to(opt.train.device)
    logging.info("åŠ è½½å·²ä¿å­˜æ¨¡å‹å‚æ•°")
    test_model_dict = {'net_f': model.net_f, 'net_b': model.net_b, 'optimizer': model.optimizer}
    epoch = load_model(test_model_dict, checkpoint_path=opt.path.checkpoint_path, device=opt.train.device)
    model_name = opt.path.checkpoint_path.split('/')[-1].split('.')[0]
    
    test_model(model, test_loader, epoch, opt, model_name)


if __name__ == '__main__':
    main()